# Glossary

## A

**Action**: In ROS 2, a communication pattern that allows clients to send goals to action servers, which then execute the goals and return results. Actions are used for long-running tasks that may need feedback.

**AI Agent**: An intelligent system that perceives its environment and takes actions to achieve specific goals. In robotics, AI agents can control robot behavior based on sensor inputs and learned models.

**Artificial Intelligence (AI)**: The simulation of human intelligence processes by machines, especially computer systems. In robotics, AI enables perception, decision-making, and learning capabilities.

**Autonomous System**: A system that can operate independently without human intervention, making decisions based on its programming and environmental inputs.

## B

**Behavior Tree**: A hierarchical tree structure used in robotics and AI to organize and execute complex behaviors. It provides a way to compose actions and conditions in a modular, reusable manner.

**Bidirectional Recurrent Neural Network (BiRNN)**: A type of neural network that processes data in both forward and backward directions, commonly used in speech recognition and natural language processing.

## C

**Cognitive Architecture**: The structure and organization of cognitive processes in an intelligent system, including perception, memory, reasoning, and action selection.

**Cognitive Planning**: The process of creating a sequence of actions to achieve a goal, considering the current state, available actions, and desired outcome. In robotics, this involves high-level reasoning about tasks.

**Command and Control Interface**: A user interface that allows human operators to send commands to and monitor autonomous systems.

**Computer Vision**: A field of artificial intelligence that trains computers to interpret and understand the visual world. In robotics, computer vision enables robots to identify objects, navigate, and interact with their environment.

**Control Theory**: A branch of engineering and mathematics that deals with the behavior of dynamical systems with inputs, and how their behavior is modified by feedback.

**Convolutional Neural Network (CNN)**: A class of deep neural networks commonly applied to analyzing visual imagery. CNNs are used in robotics for object detection, recognition, and scene understanding.

## D

**Deep Learning**: A subset of machine learning that uses neural networks with multiple layers to model and understand complex patterns in data.

**Deep Reinforcement Learning**: A type of machine learning that combines deep learning with reinforcement learning, enabling agents to learn optimal behaviors through interaction with an environment.

**Digital Twin**: A virtual representation of a physical system that mirrors the real-world object in real-time, used for simulation, monitoring, and optimization.

**Domain Randomization**: A technique in machine learning where training data is augmented with variations to improve the robustness and generalization of models, particularly important in sim-to-real transfer.

## E

**Embodied AI**: Artificial intelligence that is integrated into physical systems, allowing AI to interact with and learn from the physical world through a body or robot platform.

**Embodied Cognition**: The theory that cognitive processes are deeply influenced by the body's interactions with the environment, fundamental to understanding how robots can develop intelligent behavior.

**Encoder**: A device or algorithm that converts information from one format to another. In robotics, encoders measure the position, velocity, or acceleration of robot joints or wheels.

**End Effector**: The device at the end of a robotic arm that interacts with the environment, such as a gripper, tool, or sensor.

**Episodic Memory**: A category of long-term memory that involves the recollection of specific events, situations, and experiences, important for robot learning and adaptation.

## F

**Field-Programmable Gate Array (FPGA)**: A type of integrated circuit that can be programmed after manufacturing, often used in robotics for real-time processing and control applications.

**Forward Kinematics**: The process of determining the position and orientation of a robot's end effector based on the joint angles and link parameters.

**Fiducial Marker**: A visual marker used in computer vision and robotics for tracking and localization, such as ArUco markers.

## G

**Gazebo**: A 3D simulation environment commonly used in robotics for testing algorithms, robot designs, and scenarios without real-world risk.

**General Artificial Intelligence (GAI)**: A type of AI that can understand, learn, and apply knowledge across a wide range of tasks at a human level, as opposed to narrow AI focused on specific tasks.

**Generative Adversarial Network (GAN)**: A class of machine learning frameworks where two neural networks contest with each other to generate new data, used in robotics for synthetic data generation.

**Geometric Reasoning**: The ability to understand and reason about spatial relationships, shapes, and movements, crucial for robot navigation and manipulation.

**Gimbal Lock**: A phenomenon in 3D rotation systems where two of the three rotational axes align, causing loss of one degree of freedom.

## H

**Hardware-in-the-Loop (HIL)**: A testing methodology where real hardware components are integrated into a simulation environment to validate system behavior.

**Haptic Feedback**: Technology that recreates the sense of touch by applying forces, vibrations, or motions to the user, important for robot teleoperation.

**Human-Robot Interaction (HRI)**: The study of interactions between humans and robots, focusing on design, evaluation, and implementation of robotic systems for human use.

**Hypothetical Document Embeddings (HyDE)**: A technique in natural language processing that generates hypothetical documents to improve semantic search and retrieval.

## I

**Inverse Kinematics**: The process of determining the joint parameters needed to place a robot's end effector at a desired position and orientation.

**Isaac ROS**: NVIDIA's collection of hardware-accelerated perception and navigation packages for ROS 2, designed to run on NVIDIA Jetson platforms.

**Isaac Sim**: NVIDIA's robotics simulation environment that provides photorealistic simulation and synthetic data generation capabilities.

**Intention Inference**: The process by which a robot determines human intentions based on observed actions, gestures, or verbal cues.

## J

**Joint Space**: The space defined by the joint angles of a robot, as opposed to Cartesian space which is defined by position and orientation.

**Jacobian Matrix**: A matrix that contains first-order partial derivatives of a vector-valued function, used in robotics for relating joint velocities to end-effector velocities.

## K

**Kinematics**: The study of motion without considering the forces that cause it. In robotics, kinematics describes the relationship between joint positions and end-effector positions.

**Kinodynamic Planning**: A type of motion planning that considers both kinematic constraints (position, orientation) and dynamic constraints (velocity, acceleration).

## L

**Large Language Model (LLM)**: A type of artificial intelligence model that can understand and generate human language, used in robotics for natural language processing and command interpretation.

**Laser Range Finder (LRF)**: A sensor that measures distances using laser light, commonly used for navigation and mapping.

**Latent Space**: A lower-dimensional space that captures the essential features of higher-dimensional data, used in machine learning for dimensionality reduction and generative models.

**LiDAR (Light Detection and Ranging)**: A remote sensing method that uses light in the form of a pulsed laser to measure distances, commonly used for 3D mapping and navigation.

**Long Short-Term Memory (LSTM)**: A type of recurrent neural network architecture that can learn long-term dependencies, useful for sequential decision making in robotics.

## M

**Manipulation**: The ability of a robot to physically interact with objects in its environment, including grasping, moving, and repositioning objects.

**Markov Decision Process (MDP)**: A mathematical framework for modeling decision-making in situations where outcomes are partly random and partly under the control of a decision maker.

**Mobile Robot**: A robot that can move around in its environment, as opposed to fixed-base robots.

**Motion Planning**: The process of determining a sequence of movements that will take a robot from its current state to a desired goal state while avoiding obstacles.

**Multi-Modal Perception**: The integration of information from multiple sensory modalities (vision, audio, tactile, etc.) to create a comprehensive understanding of the environment.

**Multi-Robot System**: A system composed of multiple robots that work together to achieve common goals, requiring coordination and communication.

## N

**Natural Language Processing (NLP)**: A field of AI focused on the interaction between computers and human language, enabling robots to understand and respond to voice commands.

**Neural Radiance Fields (NeRF)**: A technique for synthesizing novel views of complex 3D scenes from a sparse set of 2D images, used in 3D reconstruction and simulation.

**NVIDIA Isaac**: NVIDIA's robotics platform that includes hardware, software, and simulation tools for developing and deploying AI-powered robots.

**Node**: In ROS, a process that performs computation. Nodes are organized in a graph and communicate with each other using topics, services, or actions.

## O

**Obstacle Avoidance**: The capability of a robot to detect and navigate around obstacles in its path, essential for autonomous navigation.

**Occupancy Grid**: A probabilistic representation of space where each cell in a grid contains the probability of being occupied by an obstacle.

**OpenAI Whisper**: An automatic speech recognition (ASR) system developed by OpenAI that converts speech to text, used in voice-controlled robotic systems.

**Operational Space**: The space in which the robot's end effector operates, typically defined by position and orientation in Cartesian coordinates.

## P

**Path Planning**: The process of determining a geometric path from a start point to a goal point, without considering dynamic constraints.

**Perception System**: The component of a robot that processes sensor data to understand its environment, including object detection, localization, and scene understanding.

**Point Cloud**: A set of data points in space, typically representing the external surface of an object, used in 3D mapping and object recognition.

**Probabilistic Robotics**: An approach to robotics that explicitly accounts for uncertainty in robot perception and action using probability theory.

**Prompt Engineering**: The practice of designing effective prompts for large language models to generate desired responses, important for human-robot interaction.

## Q

**Quality of Service (QoS)**: In ROS 2, policies that define the communication behavior between publishers and subscribers, including reliability, durability, and history settings.

**Quaternion**: A mathematical representation of rotation in 3D space, preferred over Euler angles to avoid gimbal lock.

## R

**Real-Time System**: A system that must respond to inputs within strict time constraints, critical for robot control and safety.

**Recurrent Neural Network (RNN)**: A type of neural network designed to recognize patterns in sequences of data, useful for processing temporal information in robotics.

**Reinforcement Learning**: A type of machine learning where an agent learns to make decisions by performing actions and receiving rewards or penalties.

**Robot Operating System (ROS)**: A flexible framework for writing robot software, providing services like hardware abstraction, device drivers, and message passing.

**Robotics Middleware**: Software infrastructure that provides services for robot application development, including communication, resource management, and system integration.

**Robot Kinematics**: The study of robot motion that describes the relationship between joint space and task space, including forward and inverse kinematics.

**ROS 2**: The second generation of Robot Operating System, providing improved security, real-time capabilities, and support for multiple programming languages.

## S

**Sensor Fusion**: The process of combining data from multiple sensors to achieve better accuracy and reliability than could be achieved with a single sensor.

**Service**: In ROS, a synchronous communication pattern where a client sends a request to a server and waits for a response.

**Sim-to-Real Transfer**: The process of transferring skills learned in simulation to real-world robotic systems, a key challenge in robotics research.

**Simultaneous Localization and Mapping (SLAM)**: The computational problem of constructing or updating a map of an unknown environment while simultaneously keeping track of an agent's location within it.

**State Estimation**: The process of estimating the internal state of a system from noisy measurements, fundamental to robot navigation and control.

**System Integration**: The process of combining various subsystems into a single working system, ensuring all components work together effectively.

## T

**Task Planning**: The process of creating a sequence of actions to achieve a specific goal, considering the current state and desired outcome.

**Teleoperation**: The remote operation of a robot by a human operator, often used for tasks requiring human judgment or in dangerous environments.

**Temporal Reasoning**: The ability to reason about time and temporal relationships, important for planning and scheduling robot activities.

**Topic**: In ROS, a communication channel through which nodes exchange messages, enabling publisher-subscriber communication patterns.

**Trajectory Planning**: The process of determining a time-parameterized path that specifies position, velocity, and acceleration over time.

## U

**Unified Robot Description Format (URDF)**: An XML format for representing robot models in ROS, including links, joints, and other properties.

**Unstructured Environment**: An environment without predefined structure or organization, challenging for autonomous robots to navigate and operate in.

**User Experience (UX)**: The overall experience of a person using a product such as a robot, including aspects of interaction, usability, and satisfaction.

## V

**Velodyne**: A brand of LiDAR sensors commonly used in robotics for 3D mapping and navigation.

**Vision-Language-Action (VLA)**: A framework that integrates visual perception, language understanding, and action execution in robotic systems.

**Visual SLAM**: Simultaneous Localization and Mapping that uses visual sensors (cameras) as the primary input for mapping and localization.

## W

**Whisper**: OpenAI's automatic speech recognition system that converts speech to text, used in voice-controlled robotic applications.

**Workspace**: The space within which a robot can operate, either the physical space reachable by the robot or the space of possible end-effector positions.

## X

**Xbox Controller**: A game controller often used as a human-robot interface for teleoperation and manual control of robots.

## Y

**Yaw**: The rotation of a robot around its vertical axis, one of the three rotational degrees of freedom (roll, pitch, yaw).

## Z

**Zero-Shot Learning**: A machine learning paradigm where a model can recognize objects or perform tasks it has never seen during training, important for robot adaptability.

**Z-Buffer**: A graphics rendering technique used in simulation to determine the visibility of objects in 3D space.

---

## Acronyms and Abbreviations

- **AI**: Artificial Intelligence
- **API**: Application Programming Interface
- **AR**: Augmented Reality
- **CPU**: Central Processing Unit
- **CNN**: Convolutional Neural Network
- **DDS**: Data Distribution Service
- **GAN**: Generative Adversarial Network
- **GPU**: Graphics Processing Unit
- **HRI**: Human-Robot Interaction
- **IoT**: Internet of Things
- **LIDAR**: Light Detection and Ranging
- **LLM**: Large Language Model
- **MDP**: Markov Decision Process
- **NLP**: Natural Language Processing
- **QoS**: Quality of Service
- **ROS**: Robot Operating System
- **SLAM**: Simultaneous Localization and Mapping
- **URDF**: Unified Robot Description Format
- **VLA**: Vision-Language-Action
- **VR**: Virtual Reality
- **WSL**: Windows Subsystem for Linux